#!/usr/bin/env python3
"""
AI-Enhanced Comprehensive Vulnerability Scanner
Orchestrates multiple scanning modules with Ollama Cloud AI integration
"""

import argparse
import sys
import os
from colorama import Fore, Style, init
import json
from datetime import datetime

# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from tools.ai_analyzer import OllamaAnalyzer

init(autoreset=True)


class AIVulnerabilityScanner:
    def __init__(self, target: str, output_dir: str = "./results", use_ai: bool = True):
        self.target = target
        self.output_dir = output_dir
        self.use_ai = use_ai
        self.results = {
            'target': target,
            'scan_date': datetime.now().isoformat(),
            'vulnerabilities': [],
            'reconnaissance': {},
            'ai_enabled': use_ai
        }
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Initialize AI analyzer if enabled
        self.ai_analyzer = None
        if self.use_ai:
            try:
                self.ai_analyzer = OllamaAnalyzer()
                print(f"{Fore.GREEN}[+] AI analysis enabled{Style.RESET_ALL}")
            except Exception as e:
                print(f"{Fore.YELLOW}[!] AI analysis disabled: {str(e)}{Style.RESET_ALL}")
                print(f"{Fore.YELLOW}[!] Make sure OLLAMA_API_KEY is set in .env file{Style.RESET_ALL}")
                self.use_ai = False
    
    def print_banner(self):
        ai_status = "ENABLED ✨" if self.use_ai else "DISABLED"
        banner = f"""
{Fore.CYAN}╔═══════════════════════════════════════════════════════╗
║                                                       ║
║     AI-Enhanced Bug Bounty Vulnerability Scanner     ║
║     Powered by Ollama Cloud                          ║
║                                                       ║
║     Target: {self.target:<40}║
║     AI Analysis: {ai_status:<35}║
║                                                       ║
╚═══════════════════════════════════════════════════════╝{Style.RESET_ALL}

{Fore.YELLOW}[!] LEGAL WARNING:{Style.RESET_ALL}
Only use this tool on targets you have explicit permission to test.
Unauthorized testing is illegal and unethical.

{Fore.CYAN}{'='*59}{Style.RESET_ALL}
        """
        print(banner)
    
    def run_reconnaissance(self):
        """Run reconnaissance phase"""
        print(f"\n{Fore.CYAN}{'='*59}{Style.RESET_ALL}")
        print(f"{Fore.CYAN}Phase 1: Reconnaissance{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'='*59}{Style.RESET_ALL}\n")
        
        # Import and run subdomain finder
        try:
            from recon.subdomain_finder import SubdomainFinder
            print(f"{Fore.YELLOW}[*] Running subdomain enumeration...{Style.RESET_ALL}")
            finder = SubdomainFinder(self.target, self.output_dir)
            subdomains = finder.run()
            self.results['reconnaissance']['subdomains'] = list(subdomains)
            print(f"{Fore.GREEN}[+] Found {len(subdomains)} subdomains{Style.RESET_ALL}\n")
        except Exception as e:
            print(f"{Fore.RED}[-] Subdomain enumeration failed: {str(e)}{Style.RESET_ALL}\n")
        
        # Import and run technology detection
        try:
            from recon.tech_detector import TechDetector
            print(f"{Fore.YELLOW}[*] Running technology detection...{Style.RESET_ALL}")
            detector = TechDetector(f"http://{self.target}", self.output_dir)
            detector.run()
            self.results['reconnaissance']['technologies'] = detector.technologies
            print(f"{Fore.GREEN}[+] Technology detection complete{Style.RESET_ALL}\n")
        except Exception as e:
            print(f"{Fore.RED}[-] Technology detection failed: {str(e)}{Style.RESET_ALL}\n")
    
    def run_vulnerability_scans(self):
        """Run vulnerability scanning phase with AI enhancement"""
        print(f"\n{Fore.CYAN}{'='*59}{Style.RESET_ALL}")
        print(f"{Fore.CYAN}Phase 2: AI-Enhanced Vulnerability Scanning{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'='*59}{Style.RESET_ALL}\n")
        
        target_url = f"http://{self.target}"
        
        # AI-Enhanced XSS Scan
        try:
            from scanners.xss_scanner_ai import AIEnhancedXSSScanner
            print(f"{Fore.YELLOW}[*] Running AI-enhanced XSS scan...{Style.RESET_ALL}")
            xss_scanner = AIEnhancedXSSScanner(target_url, self.output_dir, use_ai=self.use_ai)
            xss_scanner.run()
            self.results['vulnerabilities'].extend(xss_scanner.vulnerabilities)
            if hasattr(xss_scanner, 'js_analysis_results'):
                self.results['javascript_analysis'] = xss_scanner.js_analysis_results
            print(f"{Fore.GREEN}[+] XSS scan complete{Style.RESET_ALL}\n")
        except Exception as e:
            print(f"{Fore.RED}[-] XSS scan failed: {str(e)}{Style.RESET_ALL}\n")
            # Fallback to regular XSS scanner
            try:
                from scanners.xss_scanner import XSSScanner
                print(f"{Fore.YELLOW}[*] Falling back to standard XSS scanner...{Style.RESET_ALL}")
                xss_scanner = XSSScanner(target_url, self.output_dir)
                xss_scanner.run()
                self.results['vulnerabilities'].extend(xss_scanner.vulnerabilities)
            except Exception as e2:
                print(f"{Fore.RED}[-] Standard XSS scan also failed: {str(e2)}{Style.RESET_ALL}\n")
        
        # SQL Injection Scan
        try:
            from scanners.sqli_scanner import SQLiScanner
            print(f"{Fore.YELLOW}[*] Running SQL injection scan...{Style.RESET_ALL}")
            sqli_scanner = SQLiScanner(target_url, self.output_dir)
            sqli_scanner.run()
            self.results['vulnerabilities'].extend(sqli_scanner.vulnerabilities)
            print(f"{Fore.GREEN}[+] SQL injection scan complete{Style.RESET_ALL}\n")
        except Exception as e:
            print(f"{Fore.RED}[-] SQL injection scan failed: {str(e)}{Style.RESET_ALL}\n")
        
        # Directory Scan
        try:
            from scanners.directory_scanner import DirectoryScanner
            print(f"{Fore.YELLOW}[*] Running directory scan...{Style.RESET_ALL}")
            dir_scanner = DirectoryScanner(target_url, self.output_dir)
            dir_scanner.run()
            self.results['reconnaissance']['directories'] = dir_scanner.found_paths
            print(f"{Fore.GREEN}[+] Directory scan complete{Style.RESET_ALL}\n")
        except Exception as e:
            print(f"{Fore.RED}[-] Directory scan failed: {str(e)}{Style.RESET_ALL}\n")
    
    def apply_ai_analysis(self):
        """Apply AI analysis to all findings"""
        if not self.use_ai or not self.ai_analyzer or not self.results['vulnerabilities']:
            return
        
        print(f"\n{Fore.CYAN}{'='*59}{Style.RESET_ALL}")
        print(f"{Fore.CYAN}Phase 3: AI Analysis & False Positive Detection{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'='*59}{Style.RESET_ALL}\n")
        
        print(f"{Fore.CYAN}[AI] Analyzing {len(self.results['vulnerabilities'])} vulnerabilities...{Style.RESET_ALL}")
        
        # Analyze each vulnerability
        for i in range(len(self.results['vulnerabilities'])):
            self.results['vulnerabilities'][i] = self.ai_analyzer.analyze_vulnerability(
                self.results['vulnerabilities'][i]
            )
        
        # Detect false positives
        self.results['vulnerabilities'] = self.ai_analyzer.detect_false_positives(
            self.results['vulnerabilities']
        )
        
        # Filter out high-confidence false positives
        original_count = len(self.results['vulnerabilities'])
        self.results['vulnerabilities'] = [
            v for v in self.results['vulnerabilities']
            if not (v.get('false_positive_check', {}).get('is_false_positive') and
                   int(str(v.get('false_positive_check', {}).get('confidence', 0)).replace('%', '').replace('high', '90')) > 80)
        ]
        
        filtered_count = original_count - len(self.results['vulnerabilities'])
        if filtered_count > 0:
            print(f"{Fore.GREEN}[AI] Filtered out {filtered_count} high-confidence false positives{Style.RESET_ALL}\n")
    
    def generate_report(self):
        """Generate comprehensive report with AI insights"""
        print(f"\n{Fore.CYAN}{'='*59}{Style.RESET_ALL}")
        print(f"{Fore.CYAN}Phase 4: Report Generation{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'='*59}{Style.RESET_ALL}\n")
        
        # Count vulnerabilities by severity
        critical = sum(1 for v in self.results['vulnerabilities'] if v.get('severity') == 'Critical')
        high = sum(1 for v in self.results['vulnerabilities'] if v.get('severity') == 'High')
        medium = sum(1 for v in self.results['vulnerabilities'] if v.get('severity') == 'Medium')
        low = sum(1 for v in self.results['vulnerabilities'] if v.get('severity') == 'Low')
        
        print(f"{Fore.YELLOW}Total Vulnerabilities Found: {len(self.results['vulnerabilities'])}{Style.RESET_ALL}")
        if critical > 0:
            print(f"{Fore.RED}  - Critical: {critical}{Style.RESET_ALL}")
        if high > 0:
            print(f"{Fore.RED}  - High: {high}{Style.RESET_ALL}")
        if medium > 0:
            print(f"{Fore.YELLOW}  - Medium: {medium}{Style.RESET_ALL}")
        if low > 0:
            print(f"{Fore.GREEN}  - Low: {low}{Style.RESET_ALL}")
        
        # AI-specific stats
        if self.use_ai:
            ai_detected = sum(1 for v in self.results['vulnerabilities'] if v.get('ai_detected'))
            false_positives = sum(1 for v in self.results['vulnerabilities'] 
                                 if v.get('false_positive_check', {}).get('is_false_positive'))
            
            print(f"\n{Fore.CYAN}AI Analysis Stats:{Style.RESET_ALL}")
            print(f"  - AI-detected vulnerabilities: {ai_detected}")
            print(f"  - Potential false positives: {false_positives}")
        
        print(f"\n{Fore.CYAN}Reconnaissance Results:{Style.RESET_ALL}")
        if 'subdomains' in self.results['reconnaissance']:
            print(f"  - Subdomains: {len(self.results['reconnaissance']['subdomains'])}")
        if 'directories' in self.results['reconnaissance']:
            print(f"  - Directories/Files: {len(self.results['reconnaissance']['directories'])}")
        
        # Save comprehensive JSON report
        report_file = os.path.join(self.output_dir, f"{self.target}_ai_comprehensive_report.json")
        with open(report_file, 'w') as f:
            json.dump(self.results, f, indent=2)
        
        print(f"\n{Fore.GREEN}[+] JSON report saved to: {report_file}{Style.RESET_ALL}")
        
        # Generate AI-enhanced markdown and HTML reports
        try:
            from reports.ai_report_generator import AIReportGenerator
            print(f"{Fore.YELLOW}[*] Generating AI-enhanced reports...{Style.RESET_ALL}")
            
            report_gen = AIReportGenerator(self.output_dir, use_ai=self.use_ai)
            
            # Generate markdown report
            md_report = report_gen.generate_comprehensive_report(self.results)
            md_filename = f"{self.target}_ai_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
            report_gen.save_report(md_report, md_filename)
            
            # Generate HTML report
            html_report = report_gen.generate_html_report(self.results)
            html_filename = md_filename.replace('.md', '.html')
            report_gen.save_report(html_report, html_filename)
            
            print(f"{Fore.GREEN}[+] AI-enhanced reports generated{Style.RESET_ALL}")
            
        except Exception as e:
            print(f"{Fore.YELLOW}[!] Could not generate AI reports: {str(e)}{Style.RESET_ALL}")
    
    def run(self, skip_recon: bool = False, skip_vuln: bool = False):
        """Execute full AI-enhanced scan"""
        self.print_banner()
        
        if not skip_recon:
            self.run_reconnaissance()
        
        if not skip_vuln:
            self.run_vulnerability_scans()
        
        # Apply AI analysis if enabled
        if self.use_ai and self.results['vulnerabilities']:
            self.apply_ai_analysis()
        
        self.generate_report()
        
        print(f"\n{Fore.CYAN}{'='*59}{Style.RESET_ALL}")
        print(f"{Fore.GREEN}[+] AI-Enhanced Scan Complete!{Style.RESET_ALL}")
        if self.use_ai:
            print(f"{Fore.CYAN}[AI] Powered by Ollama Cloud ✨{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'='*59}{Style.RESET_ALL}\n")


def main():
    parser = argparse.ArgumentParser(
        description="AI-Enhanced Comprehensive Vulnerability Scanner",
        epilog="Example: python ai_vulnerability_scanner.py -t example.com"
    )
    parser.add_argument("-t", "--target", required=True, help="Target domain (e.g., example.com)")
    parser.add_argument("-o", "--output", default="./results", help="Output directory")
    parser.add_argument("--skip-recon", action="store_true", help="Skip reconnaissance phase")
    parser.add_argument("--skip-vuln", action="store_true", help="Skip vulnerability scanning phase")
    parser.add_argument("--no-ai", action="store_true", help="Disable AI analysis")
    
    args = parser.parse_args()
    
    scanner = AIVulnerabilityScanner(args.target, args.output, use_ai=not args.no_ai)
    scanner.run(skip_recon=args.skip_recon, skip_vuln=args.skip_vuln)


if __name__ == "__main__":
    main()
